{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b637798",
   "metadata": {},
   "source": [
    "# Практика кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ff551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Хочу заказать пиццу пепперони и колу</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Отмените мой последний заказ пожалуйста</td>\n",
       "      <td>cancel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как оплатить заказ картой онлайн?</td>\n",
       "      <td>payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Курьер опоздал на 40 минут, требую компенсацию</td>\n",
       "      <td>complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Две пасты карбонара и салат цезарь на адрес Тв...</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Закажите пиццу вегетарианскую</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Атменить заказ #888</td>\n",
       "      <td>cancel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Оплата не проходит чз прил</td>\n",
       "      <td>payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Пицца недопеченая!</td>\n",
       "      <td>complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Срочно нужен кофе!</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text     intent\n",
       "0                 Хочу заказать пиццу пепперони и колу      order\n",
       "1              Отмените мой последний заказ пожалуйста     cancel\n",
       "2                    Как оплатить заказ картой онлайн?    payment\n",
       "3       Курьер опоздал на 40 минут, требую компенсацию  complaint\n",
       "4    Две пасты карбонара и салат цезарь на адрес Тв...      order\n",
       "..                                                 ...        ...\n",
       "104                      Закажите пиццу вегетарианскую      order\n",
       "105                                Атменить заказ #888     cancel\n",
       "106                         Оплата не проходит чз прил    payment\n",
       "107                                 Пицца недопеченая!  complaint\n",
       "108                                 Срочно нужен кофе!      order\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c2eb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109 entries, 0 to 108\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    109 non-null    object\n",
      " 1   intent  109 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e9defb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Хочу заказать пиццу пепперони и колу</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text intent\n",
       "count                                    109    109\n",
       "unique                                   109      5\n",
       "top     Хочу заказать пиццу пепперони и колу  order\n",
       "freq                                       1     25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0387ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent\n",
       "order        25\n",
       "other        24\n",
       "complaint    22\n",
       "payment      20\n",
       "cancel       18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b065d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.486238532110093\n"
     ]
    }
   ],
   "source": [
    "counter = []\n",
    "words = {}\n",
    "symbols = {}\n",
    "for i in df['text']:\n",
    "    counter.append(len(i))\n",
    "    a = i.split(\" \")\n",
    "    for el in a:\n",
    "        el = str.lower(el)\n",
    "        if el not in words:\n",
    "            words[el]= 1\n",
    "        else:\n",
    "            words[el]+=1\n",
    "    for l in i:\n",
    "        l = str.lower(l)\n",
    "        if l not in symbols:\n",
    "            symbols[l] = 1\n",
    "        else:\n",
    "            symbols[l] +=1\n",
    "print(np.mean(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fed6938a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'хочу': 3,\n",
       " 'заказать': 4,\n",
       " 'пиццу': 5,\n",
       " 'пепперони': 1,\n",
       " 'и': 11,\n",
       " 'колу': 1,\n",
       " 'отмените': 7,\n",
       " 'мой': 3,\n",
       " 'последний': 1,\n",
       " 'заказ': 13,\n",
       " 'пожалуйста': 2,\n",
       " 'как': 13,\n",
       " 'оплатить': 4,\n",
       " 'картой': 1,\n",
       " 'онлайн?': 1,\n",
       " 'курьер': 8,\n",
       " 'опоздал': 1,\n",
       " 'на': 13,\n",
       " '40': 1,\n",
       " 'минут,': 1,\n",
       " 'требую': 1,\n",
       " 'компенсацию': 1,\n",
       " 'две': 4,\n",
       " 'пасты': 1,\n",
       " 'карбонара': 1,\n",
       " 'салат': 3,\n",
       " 'цезарь': 2,\n",
       " 'адрес': 1,\n",
       " 'тверская': 1,\n",
       " '15': 1,\n",
       " 'не': 12,\n",
       " 'привезли': 2,\n",
       " 'соус': 1,\n",
       " 'заказано,': 1,\n",
       " 'верните': 2,\n",
       " 'деньги': 2,\n",
       " 'где': 6,\n",
       " 'посмотреть': 1,\n",
       " 'историю': 1,\n",
       " 'заказов?': 1,\n",
       " 'можно': 9,\n",
       " 'ли': 5,\n",
       " 'изменить': 1,\n",
       " 'способ': 1,\n",
       " 'оплаты': 1,\n",
       " 'после': 2,\n",
       " 'оформления?': 1,\n",
       " '#789:': 1,\n",
       " 'отмена': 4,\n",
       " 'из-за': 2,\n",
       " 'смены': 1,\n",
       " 'планов': 1,\n",
       " 'доставьте': 3,\n",
       " 'роллы': 3,\n",
       " 'филадельфия': 1,\n",
       " 'суп': 2,\n",
       " 'том-ям': 1,\n",
       " 'почему': 8,\n",
       " 'с': 13,\n",
       " 'меня': 1,\n",
       " 'списали': 1,\n",
       " 'сумму': 1,\n",
       " 'больше': 2,\n",
       " 'заявленной?': 1,\n",
       " 'в': 11,\n",
       " 'салате': 1,\n",
       " 'был': 2,\n",
       " 'посторонний': 1,\n",
       " 'предмет,': 1,\n",
       " 'фото': 1,\n",
       " 'прикрепляю': 1,\n",
       " 'повторить': 1,\n",
       " 'вчерашний': 1,\n",
       " '#12345,': 1,\n",
       " 'я': 2,\n",
       " 'передумал': 2,\n",
       " 'оформить': 1,\n",
       " 'предоплату': 1,\n",
       " 'через': 2,\n",
       " 'apple': 1,\n",
       " 'pay?': 1,\n",
       " 'груб,': 1,\n",
       " 'примите': 1,\n",
       " 'меры': 1,\n",
       " '3': 1,\n",
       " 'пиццы': 2,\n",
       " 'маргарита': 1,\n",
       " 'доставкой': 2,\n",
       " 'к': 6,\n",
       " '19:00?': 1,\n",
       " 'ошиблась': 1,\n",
       " 'адресом,': 1,\n",
       " 'текущий': 1,\n",
       " 'проходит': 2,\n",
       " 'оплата': 4,\n",
       " 'карты': 1,\n",
       " 'сбербанка?': 1,\n",
       " 'суши': 2,\n",
       " 'приехали': 1,\n",
       " 'теплые,': 1,\n",
       " 'качество': 1,\n",
       " 'упало': 1,\n",
       " 'закажите': 4,\n",
       " 'мне': 2,\n",
       " 'шаурмы': 1,\n",
       " 'курицей': 1,\n",
       " 'фанту': 1,\n",
       " 'уже': 3,\n",
       " 'уехал': 1,\n",
       " 'из': 1,\n",
       " 'офиса,': 1,\n",
       " 'доставку': 2,\n",
       " 'привязать': 1,\n",
       " 'новую': 1,\n",
       " 'карту': 1,\n",
       " 'аккаунту?': 1,\n",
       " 'чеке': 1,\n",
       " 'ошибка,': 1,\n",
       " 'сумма': 1,\n",
       " 'совпадает': 1,\n",
       " 'меню': 1,\n",
       " 'борщ,': 1,\n",
       " 'греческий': 1,\n",
       " 'компот': 1,\n",
       " 'обед': 1,\n",
       " 'заказа': 3,\n",
       " '#678': 1,\n",
       " 'долгой': 1,\n",
       " 'доставки': 1,\n",
       " 'автоплатеж': 1,\n",
       " 'сработал,': 1,\n",
       " 'почему?': 1,\n",
       " 'съел': 1,\n",
       " 'половину': 1,\n",
       " 'моего': 1,\n",
       " 'бургера!': 1,\n",
       " '4': 2,\n",
       " 'сыра': 1,\n",
       " 'завтра': 1,\n",
       " '13:00': 1,\n",
       " 'подписку': 3,\n",
       " 'еженедельную': 1,\n",
       " 'разделить': 1,\n",
       " 'оплату': 1,\n",
       " 'карты?': 1,\n",
       " 'супе': 1,\n",
       " 'плавает': 1,\n",
       " 'волос,': 1,\n",
       " 'это': 1,\n",
       " 'отвратительно': 1,\n",
       " 'самса': 1,\n",
       " 'говядиной': 1,\n",
       " 'шт': 1,\n",
       " 'лагман': 1,\n",
       " 'нельзя': 1,\n",
       " 'отменить': 2,\n",
       " 'подтверждения?': 1,\n",
       " 'оплатил': 1,\n",
       " 'приложение,': 1,\n",
       " 'но': 1,\n",
       " 'статус': 1,\n",
       " \"'ожидает\": 1,\n",
       " \"оплаты'\": 1,\n",
       " 'весь': 1,\n",
       " 'пролился': 1,\n",
       " 'пакете,': 1,\n",
       " 'заново': 1,\n",
       " 'бизнес-ланс': 1,\n",
       " '5': 1,\n",
       " 'персон': 2,\n",
       " '#999,': 1,\n",
       " 'берет': 1,\n",
       " 'трубку': 1,\n",
       " 'получить': 1,\n",
       " 'электронный': 1,\n",
       " 'чек': 1,\n",
       " 'для': 2,\n",
       " 'оплаты?': 1,\n",
       " 'прислали': 1,\n",
       " 'чужой': 1,\n",
       " 'заказ,': 1,\n",
       " 'мой?': 1,\n",
       " 'калифорния': 1,\n",
       " '8': 1,\n",
       " '18:30': 1,\n",
       " 'насчет': 1,\n",
       " 'завтрака,': 1,\n",
       " 'при': 2,\n",
       " 'оплате': 1,\n",
       " 'криптой': 1,\n",
       " 'нет': 2,\n",
       " 'скидки?': 1,\n",
       " 'пицце': 1,\n",
       " 'недопекли': 1,\n",
       " 'тесто,': 1,\n",
       " 'сендвич': 1,\n",
       " 'индейкой': 1,\n",
       " 'капучино': 1,\n",
       " 'кофе,': 1,\n",
       " 'нужно': 1,\n",
       " 'бонусными': 1,\n",
       " 'баллами?': 1,\n",
       " 'матерился': 1,\n",
       " 'передаче': 1,\n",
       " 'плов': 1,\n",
       " 'чай': 1,\n",
       " 'каркаде': 1,\n",
       " 'парк': 1,\n",
       " 'горького': 1,\n",
       " 'сколько': 2,\n",
       " 'у': 4,\n",
       " 'вас': 4,\n",
       " 'филиалов': 1,\n",
       " 'москве?': 1,\n",
       " 'есть': 6,\n",
       " 'веганское': 1,\n",
       " 'меню?': 4,\n",
       " 'устроиться': 1,\n",
       " 'вам': 1,\n",
       " 'курьером?': 1,\n",
       " 'новый': 1,\n",
       " 'год?': 1,\n",
       " 'программа': 1,\n",
       " 'лояльности?': 1,\n",
       " 'закажи': 4,\n",
       " 'ананасами': 1,\n",
       " 'пж': 1,\n",
       " 'атмените': 1,\n",
       " '#123': 1,\n",
       " 'заплотить?': 1,\n",
       " 'приехал': 1,\n",
       " 'пьяный!!!': 1,\n",
       " 'хачу': 1,\n",
       " 'шаверму': 1,\n",
       " 'сис': 1,\n",
       " 'бараниной': 1,\n",
       " 'отмеите': 1,\n",
       " 'закас': 1,\n",
       " '#456': 1,\n",
       " 'проходыт': 1,\n",
       " 'пица': 1,\n",
       " 'была': 1,\n",
       " 'халодная': 1,\n",
       " 'супч': 1,\n",
       " 'салаат': 1,\n",
       " 'моя': 1,\n",
       " 'еда?': 1,\n",
       " 'жду': 1,\n",
       " 'час!': 1,\n",
       " 'скидку': 1,\n",
       " 'студентов?': 1,\n",
       " 'какие': 1,\n",
       " 'часы': 1,\n",
       " 'работы?': 1,\n",
       " 'доставка': 1,\n",
       " 'за': 1,\n",
       " 'город?': 1,\n",
       " 'связаться': 1,\n",
       " 'техподдержкой?': 1,\n",
       " 'приехать': 1,\n",
       " 'самовывозом?': 1,\n",
       " 'приложении': 1,\n",
       " 'глючит': 2,\n",
       " '2': 2,\n",
       " 'бургера': 1,\n",
       " 'чиз': 1,\n",
       " 'отьмени': 1,\n",
       " 'могу': 1,\n",
       " 'найти': 2,\n",
       " 'тот': 1,\n",
       " 'опять': 1,\n",
       " 'хаюшки,': 1,\n",
       " 'районо': 1,\n",
       " 'когдд': 1,\n",
       " 'будет': 1,\n",
       " 'доставка?': 3,\n",
       " 'скиньте': 1,\n",
       " 'менюшку': 1,\n",
       " 'платная': 1,\n",
       " 'без': 1,\n",
       " 'пластика': 1,\n",
       " 'упаковку?': 1,\n",
       " 'детское': 1,\n",
       " 'звонит?': 1,\n",
       " 'дом': 1,\n",
       " 'отмени': 1,\n",
       " 'всё': 1,\n",
       " 'чертям': 1,\n",
       " 'еда': 1,\n",
       " 'холодная': 1,\n",
       " 'лед': 1,\n",
       " 'дайте': 1,\n",
       " 'срочно': 2,\n",
       " 'стоит': 1,\n",
       " 'акции': 1,\n",
       " 'сегодня?': 1,\n",
       " 'подписку?': 1,\n",
       " 'наличкой?': 1,\n",
       " 'волос': 1,\n",
       " 'супе!': 1,\n",
       " 'фу!': 1,\n",
       " 'бургер': 1,\n",
       " 'кола': 1,\n",
       " 'заказ?': 1,\n",
       " 'часа': 1,\n",
       " 'применить': 1,\n",
       " 'промокод?': 1,\n",
       " 'работу': 1,\n",
       " '#777': 1,\n",
       " 'приходит': 1,\n",
       " 'смс': 1,\n",
       " 'кодом?': 1,\n",
       " 'потерял': 1,\n",
       " 'куриный': 1,\n",
       " 'wi-fi': 1,\n",
       " 'зале?': 1,\n",
       " 'собакой': 1,\n",
       " 'кафе?': 1,\n",
       " 'состав': 1,\n",
       " 'блюд?': 1,\n",
       " 'восстановить': 1,\n",
       " 'пароль?': 1,\n",
       " 'русского': 1,\n",
       " 'вегетарианскую': 1,\n",
       " 'атменить': 1,\n",
       " '#888': 1,\n",
       " 'чз': 1,\n",
       " 'прил': 1,\n",
       " 'пицца': 1,\n",
       " 'недопеченая!': 1,\n",
       " 'нужен': 1,\n",
       " 'кофе!': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc3eb255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Х': 5,\n",
       " 'о': 234,\n",
       " 'ч': 40,\n",
       " 'у': 97,\n",
       " ' ': 431,\n",
       " 'з': 78,\n",
       " 'а': 295,\n",
       " 'к': 133,\n",
       " 'т': 182,\n",
       " 'ь': 63,\n",
       " 'п': 106,\n",
       " 'и': 166,\n",
       " 'ц': 23,\n",
       " 'е': 225,\n",
       " 'р': 122,\n",
       " 'н': 142,\n",
       " 'л': 113,\n",
       " 'О': 15,\n",
       " 'м': 82,\n",
       " 'й': 36,\n",
       " 'с': 130,\n",
       " 'д': 77,\n",
       " 'ж': 33,\n",
       " 'К': 20,\n",
       " '?': 45,\n",
       " '4': 5,\n",
       " '0': 6,\n",
       " ',': 20,\n",
       " 'б': 29,\n",
       " 'ю': 17,\n",
       " 'Д': 4,\n",
       " 'в': 70,\n",
       " 'ы': 28,\n",
       " 'Т': 1,\n",
       " 'я': 31,\n",
       " '1': 6,\n",
       " '5': 4,\n",
       " 'Н': 2,\n",
       " 'г': 26,\n",
       " 'Г': 5,\n",
       " 'М': 12,\n",
       " 'ф': 11,\n",
       " 'З': 9,\n",
       " '#': 8,\n",
       " '7': 5,\n",
       " '8': 7,\n",
       " '9': 5,\n",
       " ':': 4,\n",
       " '-': 5,\n",
       " 'Ф': 2,\n",
       " 'П': 14,\n",
       " 'ш': 12,\n",
       " 'В': 6,\n",
       " '2': 4,\n",
       " '3': 5,\n",
       " 'A': 1,\n",
       " 'p': 2,\n",
       " 'l': 1,\n",
       " 'e': 1,\n",
       " 'P': 1,\n",
       " 'a': 1,\n",
       " 'y': 1,\n",
       " 'щ': 2,\n",
       " 'х': 11,\n",
       " 'С': 8,\n",
       " 'Я': 1,\n",
       " 'Б': 2,\n",
       " '6': 2,\n",
       " 'А': 3,\n",
       " 'ъ': 1,\n",
       " '!': 9,\n",
       " 'э': 2,\n",
       " \"'\": 2,\n",
       " 'Р': 1,\n",
       " 'Е': 5,\n",
       " 'У': 3,\n",
       " 'Ж': 1,\n",
       " 'ё': 1,\n",
       " 'Ц': 1,\n",
       " 'w': 1,\n",
       " 'i': 2,\n",
       " 'f': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc80255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['intent']\n",
    "x = df['text']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cb34428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>123</th>\n",
       "      <th>12345</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>30</th>\n",
       "      <th>40</th>\n",
       "      <th>456</th>\n",
       "      <th>...</th>\n",
       "      <th>чертям</th>\n",
       "      <th>чз</th>\n",
       "      <th>чиз</th>\n",
       "      <th>чужой</th>\n",
       "      <th>шаверму</th>\n",
       "      <th>шаурмы</th>\n",
       "      <th>шт</th>\n",
       "      <th>электронный</th>\n",
       "      <th>это</th>\n",
       "      <th>ям</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.362067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.386234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          00  123     12345   13        15   18        19   30        40  456  \\\n",
       "0   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "1   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "2   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "3   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.412981  0.0   \n",
       "4   0.000000  0.0  0.000000  0.0  0.362067  0.0  0.000000  0.0  0.000000  0.0   \n",
       "5   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "6   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "7   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "8   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "9   0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "10  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "11  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "12  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "13  0.000000  0.0  0.607519  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "14  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "15  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "16  0.386234  0.0  0.000000  0.0  0.000000  0.0  0.420264  0.0  0.000000  0.0   \n",
       "17  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "18  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "19  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0   \n",
       "\n",
       "    ...  чертям   чз  чиз  чужой  шаверму  шаурмы   шт  электронный  это  \\\n",
       "0   ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "1   ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "2   ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "3   ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "4   ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "5   ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "6   ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "7   ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "8   ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "9   ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "10  ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "11  ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "12  ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "13  ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "14  ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "15  ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "16  ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "17  ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "18  ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "19  ...     0.0  0.0  0.0    0.0      0.0     0.0  0.0          0.0  0.0   \n",
       "\n",
       "         ям  \n",
       "0   0.00000  \n",
       "1   0.00000  \n",
       "2   0.00000  \n",
       "3   0.00000  \n",
       "4   0.00000  \n",
       "5   0.00000  \n",
       "6   0.00000  \n",
       "7   0.00000  \n",
       "8   0.00000  \n",
       "9   0.43318  \n",
       "10  0.00000  \n",
       "11  0.00000  \n",
       "12  0.00000  \n",
       "13  0.00000  \n",
       "14  0.00000  \n",
       "15  0.00000  \n",
       "16  0.00000  \n",
       "17  0.00000  \n",
       "18  0.00000  \n",
       "19  0.00000  \n",
       "\n",
       "[20 rows x 310 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "sklearn_pca = PCA(n_components = 2)\n",
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    return line\n",
    "vectorizer = TfidfVectorizer(preprocessor=preprocessing, max_features=5000)\n",
    "def tf_idf_get_array(data):\n",
    "    tf_idf = vectorizer.fit_transform(data)\n",
    "    tf_idf_norm = normalize(tf_idf)\n",
    "    tf_idf_array=tf_idf_norm.toarray()\n",
    "    Y_sklearn = sklearn_pca.fit_transform(tf_idf_array)\n",
    "    return tf_idf_array, Y_sklearn, tf_idf\n",
    "tf_idf_array, Y_sklearn, transformer =tf_idf_get_array(df['text'])\n",
    "pd.DataFrame(tf_idf_array, columns=vectorizer.get_feature_names_out()).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f558a6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=5000,\n",
       "                preprocessor=&lt;function preprocessing at 0x000001EDD3E5C700&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">&lt;function pre...001EDD3E5C700&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">5000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.float64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('norm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">norm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('use_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">use_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('smooth_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">smooth_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sublinear_tf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sublinear_tf&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=5000,\n",
       "                preprocessor=<function preprocessing at 0x000001EDD3E5C700>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a03da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vect = vectorizer.transform(x_train)\n",
    "x_test_vect = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea206687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=10, n_jobs=-1).fit(x_train_vect,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d410cba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7632467532467533"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_pred = model.predict(x_test_vect)\n",
    "f1_score(y_pred, y_test, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e451c9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cancel       0.75      1.00      0.86         3\n",
      "   complaint       0.75      0.75      0.75         4\n",
      "       order       1.00      0.83      0.91         6\n",
      "       other       0.40      0.67      0.50         3\n",
      "     payment       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.77        22\n",
      "   macro avg       0.78      0.78      0.76        22\n",
      "weighted avg       0.84      0.77      0.79        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b16dae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 0 0]\n",
      " [0 3 0 1 0]\n",
      " [1 0 5 0 0]\n",
      " [0 1 0 2 0]\n",
      " [0 0 0 2 4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_pred, y_test, labels=[\"cancel\", \"complaint\", \"order\", \"other\", \"payment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4c6367e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c107af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0156d4065c469889b92a77ca1785c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad93cac18564b65b9e1ef2a031fe07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00b59db73a34bfeb0f60c7b02b3112e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49b156482344cab92bcc2637dd9ae3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47d42afdbf8454caa8ff78fb85243d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50a5afdf6be4ed7ac648073f7bc9845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "85f9002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for el in df['text']:\n",
    "    encoded_text = tokenizer(el, padding=True, return_tensors='pt')\n",
    "    texts.append(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "87f108fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system?True\n",
      "CUDA version: 12.6\n",
      "ID of current CUDA device:0\n",
      "Name of current CUDA device:NVIDIA GeForce RTX 2070 Super\n",
      "How many devices 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Is CUDA supported by this system?{torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
    "    \n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")\n",
    "print(f\"How many devices {torch.cuda.device_count()}\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8de1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d1fdd0b15d42c28b8c568648df7a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    }
   ],
   "source": [
    "# Класс для создания датасета\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, y, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.comment = list(df)\n",
    "        self.targets = y\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comment)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment = str(self.comment[index])\n",
    "        comment = \" \".join(comment.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        # Получаем метки для данного примера\n",
    "        targets = torch.FloatTensor(self.targets[index])\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': targets,\n",
    "            'title': comment\n",
    "        }\n",
    "import tqdm.notebook as tq\n",
    "from torch import nn\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear = torch.nn.Linear(300, 5)\n",
    "        \n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.model(\n",
    "            input_ids, \n",
    "            attention_mask=attn_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "    \n",
    "def loss_fn(outputs, targets):\n",
    "    \"\"\"Функция потерь простенькая\"\"\"\n",
    "    return torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "\n",
    "def eval_model(validation_loader, model):\n",
    "    \"\"\"Функция для вычисления точности\"\"\"\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # validation accuracy\n",
    "            _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "            _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "            num_samples += len(targ)  # technically adding batch size\n",
    "            correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "    return float(correct_predictions)/num_samples, np.mean(losses)\n",
    "\n",
    "def train_model(training_loader, model, optimizer):\n",
    "    \"Функция обучения модели на 1 эпоху\"\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    model.train()\n",
    "    # initialize the progress bar\n",
    "    # loop = tq.tqdm(enumerate(training_loader), total=len(training_loader), \n",
    "    #                   leave=True, colour='steelblue')\n",
    "    loop = tq.tqdm(training_loader)\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(ids, mask, token_type_ids) # (batch,predict)=(32,8)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        # training accuracy\n",
    "        _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "        _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "        num_samples += len(targ)  # technically adding batch size\n",
    "        correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        # grad descent step\n",
    "        optimizer.step()\n",
    "\n",
    "    # returning: trained model, model accuracy, mean loss\n",
    "    return model, float(correct_predictions)/num_samples, np.mean(losses)\n",
    "\n",
    "train_dataset = CustomDataset(x_train,y_train, tokenizer, 128)\n",
    "test_dataset = CustomDataset(x_test, y_test, tokenizer, 128)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr =1e-7)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = eval_model(test_data_loader, model, optimizer)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "    if val_acc > best_accuracy:\n",
    "            if not os.path.exists(os.path.join('output')):\n",
    "                os.makedirs(os.path.join('output'))\n",
    "            torch.save(model.state_dict(), os.path.join(\"output\",\"best_model_state.bin\"))\n",
    "            best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dd6bd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "y_encode = le.transform(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c39f7882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 4, 1, 2, 1, 3, 4, 0, 2, 4, 1, 2, 0, 4, 1, 2, 0, 4, 1, 2, 0,\n",
       "       4, 1, 2, 0, 4, 1, 2, 0, 4, 1, 2, 0, 4, 1, 2, 0, 4, 1, 2, 0, 4, 1,\n",
       "       2, 0, 4, 1, 2, 3, 3, 3, 3, 3, 2, 0, 4, 1, 2, 0, 4, 1, 2, 1, 3, 3,\n",
       "       3, 3, 3, 3, 2, 0, 4, 1, 2, 3, 3, 3, 3, 3, 1, 2, 0, 4, 1, 2, 3, 3,\n",
       "       0, 4, 1, 2, 1, 4, 2, 0, 4, 1, 2, 3, 3, 3, 3, 3, 2, 0, 4, 1, 2])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0c937a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encode,train_size=0.8, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "752507f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, 3, 4, 1, 1, 1, 1, 0, 4, 1, 3, 3, 1, 1, 0, 3, 4, 3, 3, 3,\n",
       "       4, 3, 3, 2, 1, 3, 3, 0, 4, 3, 1, 4, 2, 0, 0, 4, 1, 4, 3, 3, 2, 1,\n",
       "       2, 4, 2, 3, 4, 4, 1, 0, 3, 2, 2, 2, 1, 2, 0, 2, 1, 3, 1, 0, 1, 0,\n",
       "       4, 0, 0, 2, 3, 2, 2, 2, 3, 1, 2, 4, 2, 0, 4, 4, 0, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e2203577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e033291940b54c318fe4e0d117102834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1] at entry 0 and [4] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[192], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     model, train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     val_acc, val_loss \u001b[38;5;241m=\u001b[39m eval_model(test_data_loader, model, optimizer)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train_acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[183], line 60\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(training_loader, model, optimizer)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# initialize the progress bar\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# loop = tq.tqdm(enumerate(training_loader), total=len(training_loader), \u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m#                   leave=True, colour='steelblue')\u001b[39;00m\n\u001b[0;32m     59\u001b[0m loop \u001b[38;5;241m=\u001b[39m tq\u001b[38;5;241m.\u001b[39mtqdm(training_loader)\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m loop:\n\u001b[0;32m     61\u001b[0m     ids \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     62\u001b[0m     mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:171\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMutableMapping):\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     clone \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(elem)\n\u001b[0;32m    170\u001b[0m     clone\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m--> 171\u001b[0m         {\n\u001b[0;32m    172\u001b[0m             key: collate(\n\u001b[0;32m    173\u001b[0m                 [d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map\n\u001b[0;32m    174\u001b[0m             )\n\u001b[0;32m    175\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem\n\u001b[0;32m    176\u001b[0m         }\n\u001b[0;32m    177\u001b[0m     )\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMutableMapping):\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# The mapping type may have extra properties, so we can't just\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# use `type(data)(...)` to create the new mapping.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# Create a clone and update it if the mapping type is mutable.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     clone \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(elem)\n\u001b[0;32m    170\u001b[0m     clone\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    171\u001b[0m         {\n\u001b[1;32m--> 172\u001b[0m             key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem\n\u001b[0;32m    176\u001b[0m         }\n\u001b[0;32m    177\u001b[0m     )\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1] at entry 0 and [4] at entry 1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = eval_model(test_data_loader, model, optimizer)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "    if val_acc > best_accuracy:\n",
    "            if not os.path.exists(os.path.join('output')):\n",
    "                os.makedirs(os.path.join('output'))\n",
    "            torch.save(model.state_dict(), os.path.join(\"output\",\"best_model_state.bin\"))\n",
    "            best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8b070130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = []\n",
    "# for el in df['text']:\n",
    "#     encoded_text = tokenizer(el, padding=True, return_tensors='pt')\n",
    "#     texts.append(encoded_text['input_ids'][0])\n",
    "# def embeded(el):\n",
    "#     tokens = tokenizer(el, padding=True, truncation=True, return_tensors='pt')\n",
    "#     tokens = {k: v for k,v in tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9bfe7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_new = tokenizer.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "596b8033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(texts, y,train_size=0.8, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fe66ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[0].reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2d00e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(random_state=10, n_jobs=-1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1f0a1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list =x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5d543bbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[182], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m  \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2649\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, padding_side, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m   2611\u001b[0m \u001b[38;5;129m@add_end_docstrings\u001b[39m(\n\u001b[0;32m   2612\u001b[0m     ENCODE_KWARGS_DOCSTRING,\n\u001b[0;32m   2613\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m   2634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2635\u001b[0m \u001b[38;5;124;03m    Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\u001b[39;00m\n\u001b[0;32m   2636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2647\u001b[0m \u001b[38;5;124;03m            method).\u001b[39;00m\n\u001b[0;32m   2648\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2649\u001b[0m     encoded_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   2650\u001b[0m         text,\n\u001b[0;32m   2651\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   2652\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2653\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2654\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   2655\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2656\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2657\u001b[0m         padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[0;32m   2658\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2659\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2660\u001b[0m     )\n\u001b[0;32m   2662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3040\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3011\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3012\u001b[0m \u001b[38;5;124;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[0;32m   3013\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3028\u001b[0m \u001b[38;5;124;03m        method).\u001b[39;00m\n\u001b[0;32m   3029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3031\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3032\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3033\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3037\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3038\u001b[0m )\n\u001b[1;32m-> 3040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[0;32m   3041\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   3042\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   3043\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   3044\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   3045\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   3046\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   3047\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   3048\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   3049\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3050\u001b[0m     padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[0;32m   3051\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   3052\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   3053\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   3054\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   3055\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   3056\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   3057\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   3058\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3059\u001b[0m     split_special_tokens\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_special_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_special_tokens),\n\u001b[0;32m   3060\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3061\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:627\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    605\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    625\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[0;32m    626\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[1;32m--> 627\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m    628\u001b[0m         batched_input,\n\u001b[0;32m    629\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m    630\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    631\u001b[0m         padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m    632\u001b[0m         truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m    633\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    634\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m    635\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    636\u001b[0m         padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[0;32m    637\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    638\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    639\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    640\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    641\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    642\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    643\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    644\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    645\u001b[0m         split_special_tokens\u001b[38;5;241m=\u001b[39msplit_special_tokens,\n\u001b[0;32m    646\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[1;32mc:\\Users\\Igor\\Documents\\GitHub\\Test-tasks-for-interviews\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:553\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m!=\u001b[39m split_special_tokens:\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n\u001b[1;32m--> 553\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: tuple[\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m#                       list[dict[str, list[list[int]]]] or list[dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m#                       list[EncodingFast]\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    565\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[0;32m    567\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[0;32m    577\u001b[0m ]\n",
      "\u001b[1;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "source": [
    "X =  tokenizer.encode(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ee967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
